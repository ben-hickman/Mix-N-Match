{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "from glob import glob\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "finding Katies songs\n",
      "730 unique songs found in KatiesData/KatieStreamingHistory0.json\n",
      "70 songs found that are also in MDS\n",
      "70 new unique songs found in KatiesData/KatieStreamingHistory0.json\n",
      "676 unique songs found in KatiesData/KatiesStreamingHistory1.json\n",
      "70 songs found that are also in MDS\n",
      "18 new unique songs found in KatiesData/KatiesStreamingHistory1.json\n",
      "1363 unique songs found in KatiesData/Katiesendsong_0.json\n",
      "126 songs found that are also in MDS\n",
      "59 new unique songs found in KatiesData/Katiesendsong_0.json\n",
      "1305 unique songs found in KatiesData/Katiesendsong_1.json\n",
      "128 songs found that are also in MDS\n",
      "41 new unique songs found in KatiesData/Katiesendsong_1.json\n",
      "1356 unique songs found in KatiesData/Katiesendsong_2.json\n",
      "135 songs found that are also in MDS\n",
      "31 new unique songs found in KatiesData/Katiesendsong_2.json\n",
      "1371 unique songs found in KatiesData/Katiesendsong_3.json\n",
      "123 songs found that are also in MDS\n",
      "20 new unique songs found in KatiesData/Katiesendsong_3.json\n",
      "69 unique songs found in KatiesData/KatiesStreamingHistory3.json\n",
      "8 songs found that are also in MDS\n",
      "0 new unique songs found in KatiesData/KatiesStreamingHistory3.json\n",
      "1334 unique songs found in KatiesData/Katiesendsong_4.json\n",
      "116 songs found that are also in MDS\n",
      "17 new unique songs found in KatiesData/Katiesendsong_4.json\n",
      "984 unique songs found in KatiesData/Katiesendsong_5.json\n",
      "95 songs found that are also in MDS\n",
      "7 new unique songs found in KatiesData/Katiesendsong_5.json\n",
      "30 unique songs found in KatiesData/KatiesLibrary.json\n",
      "3 songs found that are also in MDS\n",
      "0 new unique songs found in KatiesData/KatiesLibrary.json\n",
      "784 unique songs found in KatiesData/KatiesStreamingHistory2.json\n",
      "82 songs found that are also in MDS\n",
      "0 new unique songs found in KatiesData/KatiesStreamingHistory2.json\n",
      "Total: 263 songs found for Katies that are also in the MDS\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'trackPaths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m filePaths \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m/songs/data/\u001b[39m\u001b[39m{\u001b[39;00mi[\u001b[39m2\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi[\u001b[39m3\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi[\u001b[39m4\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m.h5\u001b[39m\u001b[39m'\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m totalUniqueSongs]\n\u001b[1;32m     40\u001b[0m validDf \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(totalUniqueSongs)\n\u001b[0;32m---> 41\u001b[0m validDf\u001b[39m.\u001b[39;49mto_csv(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrackPaths/\u001b[39;49m\u001b[39m{\u001b[39;49;00mperson\u001b[39m}\u001b[39;49;00m\u001b[39m_trackNames.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)    \n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:3551\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3540\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3542\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3543\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3544\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3548\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3549\u001b[0m )\n\u001b[0;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3552\u001b[0m     path_or_buf,\n\u001b[1;32m   3553\u001b[0m     line_terminator\u001b[39m=\u001b[39;49mline_terminator,\n\u001b[1;32m   3554\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3555\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3556\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3557\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3558\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3559\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3560\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3561\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3562\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3563\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3564\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3565\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3566\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3567\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3568\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/formats/format.py:1180\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1161\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1162\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1163\u001b[0m     line_terminator\u001b[39m=\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1179\u001b[0m )\n\u001b[0;32m-> 1180\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1182\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1183\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/formats/csvs.py:241\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[39mCreate the writer & save.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[39m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilepath_or_buffer,\n\u001b[1;32m    243\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    244\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    245\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merrors,\n\u001b[1;32m    246\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompression,\n\u001b[1;32m    247\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstorage_options,\n\u001b[1;32m    248\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    249\u001b[0m \n\u001b[1;32m    250\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    252\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    253\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mline_terminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:694\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[39m# Only for write methods\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode \u001b[39mand\u001b[39;00m is_path:\n\u001b[0;32m--> 694\u001b[0m     check_parent_directory(\u001b[39mstr\u001b[39;49m(handle))\n\u001b[1;32m    696\u001b[0m \u001b[39mif\u001b[39;00m compression:\n\u001b[1;32m    697\u001b[0m     \u001b[39mif\u001b[39;00m compression \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mzstd\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    698\u001b[0m         \u001b[39m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/common.py:568\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    566\u001b[0m parent \u001b[39m=\u001b[39m Path(path)\u001b[39m.\u001b[39mparent\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m parent\u001b[39m.\u001b[39mis_dir():\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\u001b[39mrf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot save file into a non-existent directory: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mparent\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'trackPaths'"
     ]
    }
   ],
   "source": [
    "people = ['Katies', 'Bens']\n",
    "for person in people:\n",
    "    print()\n",
    "    print(f\"finding {person} songs\")\n",
    "    files = glob(path.join(f\"{person}Data\", \"*.json\"))\n",
    "    totalUniqueSongs = set()\n",
    "    for file in files:\n",
    "        with open(f'{file}', encoding=\"utf-8\") as json_data:\n",
    "            data = json.load(json_data)\n",
    "            if 'Library' in file:\n",
    "                spotifyDf = pd.DataFrame(data['tracks'])\n",
    "                \n",
    "            else:\n",
    "                spotifyDf = pd.DataFrame(data)\n",
    "        # only keep the needed columns for sorting\n",
    "        \n",
    "        if 'Library' in file:\n",
    "            keys = ['track', 'artist']\n",
    "            \n",
    "        elif 'Streaming' in file:\n",
    "            keys = ['trackName', 'artistName']\n",
    "        else:\n",
    "            keys = ['master_metadata_track_name', 'master_metadata_album_artist_name']\n",
    "        sortingDf = spotifyDf[keys]\n",
    "        sortingDf = sortingDf.drop_duplicates()\n",
    "        print(f\"{len(sortingDf)} unique songs found in {file}\")   \n",
    "        escapedDf = sortingDf.replace(\"'\", \"''\", regex=True)\n",
    "\n",
    "        connection = sqlite3.connect('track_metadata.db')\n",
    "        # for every song in library make a sql query and retrieve the track id\n",
    "        escapedDf['id'] = escapedDf.apply(lambda x: pd.read_sql_query(f\"SELECT track_id FROM songs WHERE title='{x[0]}' AND artist_name='{x[1]}';\", connection), axis=1)\n",
    "        connection.close()\n",
    "        validId =  set([i.iloc[[0]]['track_id'].values[0] for i in escapedDf['id'] if i.empty == False])\n",
    "        print(f\"{len(validId)} songs found that are also in MDS\")\n",
    "        old_len = len(totalUniqueSongs)\n",
    "        totalUniqueSongs = totalUniqueSongs.union(validId)\n",
    "        print(f\"{len(totalUniqueSongs) - old_len} new unique songs found in {file}\")\n",
    "    print(f\"Total: {len(totalUniqueSongs)} songs found for {person} that are also in the MDS\")\n",
    "    filePaths = [f'/songs/data/{i[2]}/{i[3]}/{i[4]}/{i}.h5' for i in totalUniqueSongs]\n",
    "    validDf = pd.DataFrame(totalUniqueSongs)\n",
    "    validDf.to_csv(f\"trackPaths/{person}_trackNames.csv\", index=False)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final number of unique songs 4845\n"
     ]
    }
   ],
   "source": [
    "\n",
    "validDf = pd.DataFrame(totalUniqueSongs)\n",
    "validDf.drop_duplicates()\n",
    "print(f\"final number of unique songs {len(validDf)}\")\n",
    "validDf.to_csv(f\"ValidSongs/{person}_ValidSongs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
